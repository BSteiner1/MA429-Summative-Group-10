{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600622d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d48a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Images'\n",
    "folders = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b39e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1775e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    \n",
    "    # Label as healthy or diseased\n",
    "    if folder.endswith('healthy'):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    \n",
    "    # Iterate through the folders\n",
    "    folder_images = os.listdir(path + '/' + folder)\n",
    "    folder_path = path + '/' + folder + '/'\n",
    "    \n",
    "    # Extract images from each folder\n",
    "    for image in folder_images:\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        image_path = Image.open(image_path)\n",
    "        \n",
    "        # Convert image to pixel values\n",
    "        pixel_values = np.array(image_path)\n",
    "        \n",
    "        # Add image and label\n",
    "        data.append((pixel_values, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254762ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eee965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8421c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [pair[0] for pair in data]\n",
    "labels = [pair[1] for pair in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the proportions for train, validation, and test sets\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples for each set\n",
    "num_samples = len(data)\n",
    "num_train = int(train_ratio * num_samples)\n",
    "num_val = int(val_ratio * num_samples)\n",
    "num_test = num_samples - num_train - num_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9062e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_images = images[:num_train]\n",
    "val_images = images[num_train:num_train + num_val]\n",
    "test_images = images[num_train + num_val:]\n",
    "\n",
    "# Split the data\n",
    "train_labels = labels[:num_train]\n",
    "val_labels = labels[num_train:num_train + num_val]\n",
    "test_labels = labels[num_train + num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969836d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mean_and_var(images):\n",
    "    \n",
    "    mean = np.mean(images, axis=0)\n",
    "    variance = np.var(images, axis=0)\n",
    "    \n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = normalise_images(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33017bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalisation(images, mean, variance):\n",
    "    \n",
    "    images = (images - mean) / np.sqrt(variance)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = apply_normalisation(train_images, mean, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae533467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training data\n",
    "train_images = [image/255 for image in train_images]\n",
    "val_images = [image/255 for image in val_images]\n",
    "test_images = [image/255 for image in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check val and test mean and variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d564d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1162eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);\n",
    "plt.axis('off');  # Hide axis\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db96d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53881e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train_images[:1000]\n",
    "l = train_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b958a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(torch.tensor(t[i]), torch.tensor(l[i])) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define train and test loaders\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b044f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_tensor1, batch_tensor2 in train_loader:\n",
    "    # Print the size of the current batch tensors\n",
    "    print(\"Batch tensor 1 size:\", batch_tensor1.size())\n",
    "    print(\"Batch tensor 2 size:\", batch_tensor2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3136, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8300c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, images, test_loader):\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69390a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training lop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    acc = accuracy(model, images, test_loader)\n",
    "\n",
    "    print(f'Test Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e68d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
